{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to select the most appropriate algorithm for the problem. A good principle is to start with the simpler one and work your way up to more complex ones if the results are not satisfying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362, 18993)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import load_npz, hstack\n",
    "\n",
    "min_count = 5\n",
    "\n",
    "emails = pd.read_pickle('./data/emails.pkl')\n",
    "subjects_BoW = load_npz('./data/subjects_BoW.npz')\n",
    "contents_BoW = load_npz('./data/contents_BoW.npz')\n",
    "FromUsers = load_npz('./data/FromUsers.npz')\n",
    "ToUsers = load_npz('./data/ToUsers.npz')\n",
    "FromDomains = load_npz('./data/FromDomains.npz')\n",
    "ToDomains = load_npz('./data/ToDomains.npz')\n",
    "\n",
    "# Drop columns that have less than the min count\n",
    "subjects_BoW = subjects_BoW[:,subjects_BoW.sum(0).A[0] > min_count]\n",
    "contents_BoW = contents_BoW[:,contents_BoW.sum(0).A[0] > min_count]\n",
    "FromUsers = FromUsers[:,FromUsers.sum(0).A[0] > min_count]\n",
    "ToUsers = ToUsers[:,ToUsers.sum(0).A[0] > min_count]\n",
    "FromDomains = FromDomains[:,FromDomains.sum(0).A[0] > min_count]\n",
    "ToDomains = ToDomains[:,ToDomains.sum(0).A[0] > min_count]\n",
    "\n",
    "# Stack the data altogether\n",
    "processed_data = hstack([subjects_BoW, contents_BoW, FromUsers, ToUsers, FromDomains, ToDomains], format='csr', dtype=float)\n",
    "del subjects_BoW; del contents_BoW; del FromUsers; del ToUsers; del FromDomains; del ToDomains\n",
    "\n",
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data shuffling and creation of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = processed_data, emails['label'][:6362].values\n",
    "del processed_data\n",
    "del emails\n",
    "\n",
    "indexes = list(range(X.shape[0]))\n",
    "random.seed(1)\n",
    "random.shuffle(indexes)\n",
    "\n",
    "X, y = X[indexes], y[indexes]\n",
    "cutoff = int(X.shape[0]*0.5)\n",
    "\n",
    "X_train_valid, y_train_valid = X[:cutoff], y[:cutoff]\n",
    "X_test, y_test = X[cutoff:], y[cutoff:]\n",
    "\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning algorithm, here, the logistic regression has been selected for its low complexity and more than interesting score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialisation\n",
    "LR = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Training\n",
    "LR.fit(X_train_valid,y_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good start for scoring a classifier is to analyse their precision, recall and f1-score which is the combination of the two. Indeed, here the classes are a bid imbalanced, so this could have a good precision by just predicting the most represented class.\n",
    "\n",
    "The f1-score usually gives a balanced scoring by giving as much importance to the minority class than the majority one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      2435\n",
      "          1       0.99      1.00      1.00       746\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = LR.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the algorithm seems to be perfectly fine for the problem. We could add some boosting to grab the last bit of precision, but it would cost more calculation at prediction time, so more money overall. Plus, the logistic regression is easy to parallelize if needs be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoostedClassifier(X_train_, y_train_, X_valid_, y_valid_):\n",
    "    # Initialiser l'Extreme Gradient Boosted Classifier (XGBClassifier) avec comme objectif: binaire logistique pour avoir une regression logisitique.\n",
    "    clf = XGBClassifier(n_estimators=200,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=.1, \n",
    "                        subsample=.8, \n",
    "                        colsample_bytree=.8,\n",
    "                        gamma=1,\n",
    "                        reg_alpha=0,\n",
    "                        reg_lambda=1,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "    # Entraîner le classifieur avec la métrique gini_xgb\n",
    "    # PS: mettez verbose=True si vous voulez voir l'avancement\n",
    "    clf.fit(X_train_,y_train_,\n",
    "             eval_set=[(X_train_,y_train_),(X_valid_,y_valid_)],\n",
    "             eval_metric='error',\n",
    "             early_stopping_rounds=None,\n",
    "             verbose=False)\n",
    " \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer X_train_valid, y_train_valid en X_train, X_valid et y_train, y_valid avec un split de 0.9 (90% des données dans train et 10% dans test)\n",
    "cutoff = int(X_train_valid.shape[0]*0.9)\n",
    "X_valid, y_valid = X_train_valid[cutoff:], y_train_valid[cutoff:]\n",
    "X_train, y_train = X_train_valid[:cutoff], y_train_valid[:cutoff]\n",
    "\n",
    "# Appeler le BoostedClassifier\n",
    "xgb = BoostedClassifier(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Trouver l'estimateur qui a eu la meilleur performance Gini parmis tous les estimateurs\n",
    "xgb_evals = xgb.evals_result_[\"validation_1\"]['error']\n",
    "best_round = np.argsort(xgb_evals)[::-1][0]\n",
    "\n",
    "# Calculer les probabilités prédites par le meilleur estimateur sur l'ensemble de test\n",
    "predictions = xgb.predict(X_test, ntree_limit=best_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      2435\n",
      "          1       1.00      1.00      1.00       746\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
